[
  {
    "objectID": "post-mortem-ppi.html",
    "href": "post-mortem-ppi.html",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "",
    "text": "challenge = \"PPI\""
  },
  {
    "objectID": "post-mortem-ppi.html#past-predictions",
    "href": "post-mortem-ppi.html#past-predictions",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Past predictions",
    "text": "Past predictions\nThis interactive graph displays the historical forecasts generated by all of our models, as well as the actual observed value for the selected country.\n\naddTooltips(\n  Plot.plot({\n    grid: true,\n    y: {\n      label: \"↑ Producer prices in industry\",\n    },  \n    marks: [\n      Plot.line(historical, {\n          x: \"date\", \n          y: \"values\", \n          stroke: \"black\",\n          strokeWidth: 2,\n          title: (d) =&gt;\n                `${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })}\\n ${d.values} `\n          }),\n      Plot.line(predictions, {\n          x: \"date\", \n          y: \"values\",\n          stroke: \"model\",\n          title: (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values} `\n          })\n    ],\n    color: {legend: true}\n  })\n)"
  },
  {
    "objectID": "post-mortem-ppi.html#square-relative-error-per-month",
    "href": "post-mortem-ppi.html#square-relative-error-per-month",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Square relative error per month",
    "text": "Square relative error per month\nThis graph illustrates the square relative error for each of the models used in the challenge. The square relative error is a measure of the accuracy of a forecast that takes into account the magnitude of the error, as well as the level of the first official release being predicted.\n\\[\nSRE = \\left(\\frac{Y - R}{R}\\right)^2\n\\] where \\(R\\) is the first official release and \\(Y\\) the nowcasted value.\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      axis: null\n    },\n    y: {\n      grid: true,\n      label: \"↑ SRE\"\n    },\n    color: {\n      legend: true\n    },\n    fx: {\n      label: null,\n      tickFormat: (d) =&gt; d.toLocaleString('en-US', { month: 'long', year: 'numeric' }),    \n      reverse: false\n    },\n    facet: {data: errors, x: \"Date\"},\n    marks: [\n      Plot.barY(errors, {\n          x: \"Model\", \n          y: \"Errors\", \n          fill: \"Model\",\n          sort: {\n            x: {value: \"y\", reverse: true}\n          },\n          title: (d) =&gt;\n              `${d.Model}: \\n ${d.Errors} `\n        }),\n      Plot.ruleY([0])\n    ]\n  })\n)"
  },
  {
    "objectID": "post-mortem-ppi.html#mean-square-relative-error",
    "href": "post-mortem-ppi.html#mean-square-relative-error",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Mean square relative error",
    "text": "Mean square relative error\nThis interactive graph displays the mean square relative error for each of the models used in the challenge, ranked by their performance from the least accurate to the most accurate. The mean square relative error is a statistical measure that provides an average of the square relative error across all the forecasts made by a given model.\nThese errors can be weighted by a factor, as was the case in the official evaluation of the challenge. The role of the weights is to reflect the difficulty of predicting the point estimate of the target variable for the corresponding country.\n\\[\nMSRE = \\frac{1}{n}\\sum_\\limits{i=1}^n\\left(\\frac{Y_i - R_i}{R_i}\\right)^2\n\\]\n\nviewof doweighted = Inputs.toggle({label: \"Weighted mean\", value: false})\n\n\n\n\n\n\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      label: null\n    },\n    y: {\n      grid: true,\n      transform: doweighted ? d =&gt; d * weight : null\n    },\n    color: {\n      legend: true\n    },\n    marks: [\n      Plot.barY(ave_errors, {\n                x: \"Entries\", \n                y: \"MSRE\",\n                fill: \"Entries\",\n                sort: {\n                        x: {value: \"y\", reverse: true}\n                      },\n                title: (d) =&gt;\n                    `${d.Entries}: \\n ${doweighted ?  Math.round(d.MSRE * weight * 10000) / 10000 :  Math.round(d.MSRE * 10000) / 10000} (n = ${d.N}) `\n                }),\n      Plot.ruleY([0])\n    ]\n  })\n)\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nerrors = format_errors_data(errors_data, country_iso)\n\n\n\n\n\n\n\nave_errors = format_ave_errors_data(ave_errors_data, country_iso)\n\n\n\n\n\n\n\n\nweight = get_weights_per_challenge(mapping_countries_weights, challenge).filter(d =&gt; d.Name == country)[0].Weight\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REGARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_errors_data,\n    format_ave_errors_data,\n    mapping_countries_weights,\n    get_countries_per_challenge,\n    get_weights_per_challenge,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\""
  },
  {
    "objectID": "ppi.html",
    "href": "ppi.html",
    "title": "Producer prices in industry challenge",
    "section": "",
    "text": "challenge = \"PPI\"\nProducer prices are also known as output prices and the objective of the output price index is to measure the monthly development of transaction prices of economic activities.\nThere is a general public interest in knowing the extent to which the prices of goods and services have risen. Also, it has long been customary in many countries to adjust levels of wages, pensions, and payments in long term contracts in proportion to changes in relevant prices.\nThe domestic output price index for an economic activity measures the average price development of all goods and related services resulting from that activity and sold on the domestic market between one time period and another."
  },
  {
    "objectID": "ppi.html#next-forecast-for-a-given-country",
    "href": "ppi.html#next-forecast-for-a-given-country",
    "title": "Producer prices in industry challenge",
    "section": "Next forecast for a given country",
    "text": "Next forecast for a given country\n\nviewof country = Inputs.select(Object.values(country_map), {\n  label: html`&lt;b&gt;Select a country:&lt;/b&gt;`,\n  placeholder: \"Enter a country name\",\n  unique: true\n  })\n\n\n\n\n\n\n\n\n\naddTooltips(\nPlot.plot({\n  grid: true,\n  y: {\n    label: \"↑ Production price in industry\",\n  },  \n  x: {\n      label: \"Year\",\n      domain: range\n    },\n  marks: [\n    Plot.line(historical, {\n        x: \"date\", \n        y: \"values\", \n        stroke: \"black\",\n        title: (d) =&gt;\n              `${d.date.toLocaleString(\"en-UK\", {\n                month: \"long\",\n                year: \"numeric\"\n              })}\\n ${d.values} `\n        }),\n    Plot.dot(predictions, {\n        x: \"date\", \n        y: \"values\",\n        fill: \"model\",\n        title:  (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values} `\n        })\n  ],\n  color: {legend: true}\n})\n)\n\n\n\n\n\n\n\n\n\n\n\ndates = {\n  const data = historical.map(d =&gt; d.date)\n  data.push(predictions.map(d =&gt; d.date)[0])\n  return data  \n}\n\nviewof range = offsetInterval(dates, {\n  value: [ dates[dates.length-90], dates[dates.length-1] ],\n  format: ([a, b]) =&gt; htl.html`&lt;span ${{\n    style: \"display: flex; justify-content: space-between\"\n  }}&gt;\n    ${a.toISOString(\"en-UK\").slice(0, 10)}\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    ${b.toISOString(\"en-UK\").slice(0, 10)}\n  &lt;/span&gt;`\n})"
  },
  {
    "objectID": "ppi.html#country-specific-forecast-summary-by-model",
    "href": "ppi.html#country-specific-forecast-summary-by-model",
    "title": "Producer prices in industry challenge",
    "section": "Country-specific forecast summary by model",
    "text": "Country-specific forecast summary by model\n\nviewof form = Inputs.form({\n  model: Inputs.checkbox(models, {value: models}),\n  countries: Inputs.select([\"All\", ...Object.values(country_map)], {multiple: true, value: [\"All\"], width: 50, size: 1})\n})\n\n\n\n\n\n\n\nviewof rows = Inputs.table(summary_table,{\n  rows: 25,\n  maxWidth: 840,\n  multiple: false,\n  layout: \"fixed\"\n})\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nsummary_table = format_summary_table_data(pred, form.countries, form.model, country_map)\n\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REG-ARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_summary_table_data,\n    get_countries_per_challenge,\n    mapping_countries_weights,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\"\nimport {offsetInterval} from '@mootari/offset-slider'"
  },
  {
    "objectID": "utils/utils.html",
    "href": "utils/utils.html",
    "title": "European Statistics Awards for Nowcasting",
    "section": "",
    "text": "mapping_countries_weights = [\n  {\"Name\": \"Austria\", \"ISO2\": \"AT\", \"PPI\": 0.77, \"PVI\": 0.50, \"TOURISM\": 1.59},\n  {\"Name\": \"Belgium\", \"ISO2\": \"BE\", \"PPI\": 1.54, \"PVI\": 1.14, \"TOURISM\": 1.79},\n  {\"Name\": \"Bulgaria\", \"ISO2\": \"BG\", \"PPI\": 1.07, \"PVI\": 1.71, \"TOURISM\": undefined},\n  {\"Name\": \"Cyprus\", \"ISO2\": \"CY\", \"PPI\": 1.23, \"PVI\": 0.6, \"TOURISM\": 1.55},\n  {\"Name\": \"Czech Republic\", \"ISO2\": \"CZ\", \"PPI\": 1.32, \"PVI\": 1.71, \"TOURISM\": 1.94},\n  {\"Name\": \"Germany\", \"ISO2\": \"DE\", \"PPI\": 1.29, \"PVI\": 1.85, \"TOURISM\": 2},\n  {\"Name\": \"Denmark\", \"ISO2\": \"DK\", \"PPI\": 0.63, \"PVI\": 1.23, \"TOURISM\": 1.6},\n  {\"Name\": \"Estonia\", \"ISO2\": \"EE\", \"PPI\": 0.67, \"PVI\": 1.26, \"TOURISM\": undefined},\n  {\"Name\": \"Greece\", \"ISO2\": \"EL\", \"PPI\": 1.06, \"PVI\": 1.35, \"TOURISM\": 1.38},\n  {\"Name\": \"Spain\", \"ISO2\": \"ES\", \"PPI\": 1.73, \"PVI\": 1.37, \"TOURISM\": 1.85},\n  {\"Name\": \"Finland\", \"ISO2\": \"FI\", \"PPI\": 0.69, \"PVI\": 0.84, \"TOURISM\": 1.86},\n  {\"Name\": \"France\", \"ISO2\": \"FR\", \"PPI\": 1.52, \"PVI\": 1.16, \"TOURISM\": 1.67},\n  {\"Name\": \"Croatia\", \"ISO2\": \"HR\", \"PPI\": 0.88, \"PVI\": 1.86, \"TOURISM\": 1.27},\n  {\"Name\": \"Hungary\", \"ISO2\": \"HU\", \"PPI\": 1.25, \"PVI\": 1.16, \"TOURISM\": 1.87},\n  {\"Name\": \"Ireland\", \"ISO2\": \"IE\", \"PPI\": 1.12, \"PVI\": undefined, \"TOURISM\": undefined},\n  {\"Name\": \"Italy\", \"ISO2\": \"IT\", \"PPI\": 1.17, \"PVI\": 1.67, \"TOURISM\": 1.68},\n  {\"Name\": \"Lithuania\", \"ISO2\": \"LT\", \"PPI\": 1.16, \"PVI\": 1.08, \"TOURISM\": 1.91},\n  {\"Name\": \"Luxembourg\", \"ISO2\": \"LU\", \"PPI\": 1.13, \"PVI\": undefined, \"TOURISM\": 1.81},\n  {\"Name\": \"Latvia\", \"ISO2\": \"LV\", \"PPI\": 1.54, \"PVI\": 1.12, \"TOURISM\": 1.9},\n  {\"Name\": \"Malta\", \"ISO2\": \"MT\", \"PPI\": 2.00, \"PVI\": 1, \"TOURISM\": 1.97},\n  {\"Name\": \"Netherlands\", \"ISO2\": \"NL\", \"PPI\": 0.78, \"PVI\": undefined, \"TOURISM\": 1.78},\n  {\"Name\": \"Poland\", \"ISO2\": \"PL\", \"PPI\": 0.50, \"PVI\": 1.74, \"TOURISM\": 0.73},\n  {\"Name\": \"Portugal\", \"ISO2\": \"PT\", \"PPI\": 1.45, \"PVI\": 1.54, \"TOURISM\": 0.66},\n  {\"Name\": \"Romania\", \"ISO2\": \"RO\", \"PPI\": 1.17, \"PVI\": 2, \"TOURISM\": 0.67},\n  {\"Name\": \"Sweden\", \"ISO2\": \"SE\", \"PPI\": undefined, \"PVI\": 1.58, \"TOURISM\": 0.5},\n  {\"Name\": \"Slovenia\", \"ISO2\": \"SI\", \"PPI\": 1.91, \"PVI\": 1.24, \"TOURISM\": 0.63},\n  {\"Name\": \"Slovakia\", \"ISO2\": \"SK\", \"PPI\": 1.28, \"PVI\": 1.91, \"TOURISM\": 0.79},\n];\n\n\n\n\n\n\n\nfunction get_weights_per_challenge(mapping, challenge) {\n  return mapping.filter(d =&gt; d[challenge] != undefined).map(({ Name, ISO2, [challenge]: Weight }) =&gt; ({ Name, ISO2, Weight }))\n    }\n\n\n\n\n\n\n\nfunction get_countries_per_challenge(mapping, challenge) {\n  return mapping\n    .filter(d =&gt; d[challenge] != undefined)\n    .reduce((acc, country) =&gt; { acc[country.ISO2] = country.Name;\n                                return acc; }, {}\n                                )\n    }\n\n\n\n\n\n\n\nmap_country_name = mapping_countries_weights.reduce((acc, country) =&gt; {\n  acc[country.ISO2] = country.Name;\n  return acc;\n}, {})\n\n\n\n\n\n\n\nfunction unique(data, accessor) {\nreturn Array.from(new Set(accessor ? data.map(accessor) : data));\n    }\n\n\n\n\n\n\n\ndateParser = (dateString) =&gt; {\n  const [year, month, day] = dateString.split('-')\n  const date = new Date(Date.UTC(year, month - 1, day, 0, 0, 0))\n  const timezoneOffset = date.getTimezoneOffset()\n  date.setMinutes(date.getMinutes() - timezoneOffset)\n  return date\n}\n\n\n\n\n\n\n\nfunction format_historical_data(data, country) {\n\n  let data_typed = transpose(data).map( d =&gt; (\n      {\n        date: dateParser(d.time),\n        values: d.values,\n        geo: d.geo\n      } \n     )\n   )\n  \nreturn data_typed.filter(d =&gt; d.geo == country);\n    }\n\n\n\n\n\n\n\nfunction format_pred_data(data, country) {\n\n  let pred_typed = transpose(data).map( d =&gt; (\n      {\n        date: dateParser(d.Date),\n        values: d.value,\n        geo: d.Country,\n        model: d.Entries\n      } \n     )\n   )\n  \n  return pred_typed.filter(d =&gt; d.geo == country);\n    }\n\n\n\n\n\n\n\nfunction format_summary_table_data(data, country, model, country_map) {\n  let table = transpose(data).map( d =&gt; (\n        {\n          Date: dateParser(d.Date),\n          Model: d.Entries,\n          Country: d.Country,\n          Forecast: d.value\n        } \n       )\n     )\n    .map(item =&gt; {\n      const dateStr = item.Date;\n      const date = new Date(dateStr);\n      const formattedDate = date.toLocaleString('en-US', { month: 'long', year: 'numeric' });\n      return { ...item, Date: formattedDate };\n    })\n    .map(item =&gt; {\n      const geoCode = item.Country;\n      const countryName = country_map[geoCode];\n      return { ...item, Country: countryName };\n    })\n    .filter(d =&gt; model.includes(d.Model) && (country.includes(\"All\") || country.includes(d.Country)));\n\n  return table\n    }\n\n\n\n\n\n\n\nfunction format_errors_data(data, country) {\n\n  let data_formatted = transpose(data).map( d =&gt; (\n        {\n          Date: dateParser(d.time),\n          Model: d.Entries,\n          Country: d.geo,\n          Errors: d.error_squared\n        } \n       )\n     )\n    .filter(d =&gt; d.Country == country)\n\n  return data_formatted.filter(d =&gt; d.Country == country);\n    }\n\n\n\n\n\n\n\nfunction format_ave_errors_data(data, country) {\n  return transpose(data).filter(d =&gt; d.geo == country);\n    }"
  },
  {
    "objectID": "post-mortem-tourism.html",
    "href": "post-mortem-tourism.html",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "",
    "text": "challenge = \"TOURISM\""
  },
  {
    "objectID": "post-mortem-tourism.html#past-predictions",
    "href": "post-mortem-tourism.html#past-predictions",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Past predictions",
    "text": "Past predictions\nThis interactive graph displays the historical forecasts generated by all of our models, as well as the actual observed value for the selected country.\n\naddTooltips(\n  Plot.plot({\n    grid: true,\n    y: {\n      label: \"↑ Number of nights spent at tourist accommodation establishments (millions)\",\n      transform: d =&gt; d / 1e6\n    },  \n    marks: [\n      Plot.line(historical, {\n          x: \"date\", \n          y: \"values\", \n          stroke: \"black\",\n          strokeWidth: 2,\n          title: (d) =&gt;\n                `${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })}\\n ${d.values / 1e6} millions `\n          }),\n      Plot.line(predictions, {\n          x: \"date\", \n          y: \"values\",\n          stroke: \"model\",\n          title: (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values / 1e6} millions `\n          })\n    ],\n    color: {legend: true}\n  })\n)"
  },
  {
    "objectID": "post-mortem-tourism.html#square-relative-error-per-month",
    "href": "post-mortem-tourism.html#square-relative-error-per-month",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Square relative error per month",
    "text": "Square relative error per month\nThis graph illustrates the square relative error for each of the models used in the challenge. The square relative error is a measure of the accuracy of a forecast that takes into account the magnitude of the error, as well as the level of the first official release being predicted.\n\\[\nSRE = \\left(\\frac{Y - R}{R}\\right)^2\n\\] where \\(R\\) is the first official release and \\(Y\\) the nowcasted value.\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      axis: null\n    },\n    y: {\n      grid: true,\n      label: \"↑ SRE\",\n      transform: d =&gt; d / 1e6\n\n    },\n    color: {\n      legend: true\n    },\n    fx: {\n      label: null,\n      tickFormat: (d) =&gt; d.toLocaleString('en-US', { month: 'long', year: 'numeric' }),    \n      reverse: false\n    },\n    facet: {data: errors, x: \"Date\"},\n    marks: [\n      Plot.barY(errors, {\n          x: \"Model\", \n          y: \"Errors\", \n          fill: \"Model\",\n          sort: {\n            x: {value: \"y\", reverse: true}\n          },\n          title: (d) =&gt;\n              `${d.Model}: \\n ${Math.round(d.Errors) / 1e6} millions`\n        }),\n      Plot.ruleY([0])\n    ]\n  })\n)"
  },
  {
    "objectID": "post-mortem-tourism.html#mean-square-relative-error",
    "href": "post-mortem-tourism.html#mean-square-relative-error",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Mean square relative error",
    "text": "Mean square relative error\nThis interactive graph displays the mean square relative error for each of the models used in the challenge, ranked by their performance from the least accurate to the most accurate. The mean square relative error is a statistical measure that provides an average of the square relative error across all the forecasts made by a given model.\nThese errors can be weighted by a factor, as was the case in the official evaluation of the challenge. The role of the weights is to reflect the difficulty of predicting the point estimate of the target variable for the corresponding country.\n\\[\nMSRE = \\frac{1}{n}\\sum_\\limits{i=1}^n\\left(\\frac{Y_i - R_i}{R_i}\\right)^2\n\\]\n\nviewof doweighted = Inputs.toggle({label: \"Weighted mean\", value: false})\n\n\n\n\n\n\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      label: null\n    },\n    y: {\n      grid: true,\n      transform: doweighted ? d =&gt; d / 1e6 * weight : d =&gt; d / 1e6\n\n    },\n    color: {\n      legend: true\n    },\n    marks: [\n      Plot.barY(ave_errors, {\n                x: \"Entries\", \n                y: \"MSRE\",\n                fill: \"Entries\",\n                sort: {\n                        x: {value: \"y\", reverse: true}\n                      },\n                title: (d) =&gt;\n\n                    `${d.Entries}: \\n ${doweighted ? Math.round(d.MSRE) / 1e6 * weight : Math.round(d.MSRE) / 1e6} millions (n = ${d.N}) `\n                }),\n      Plot.ruleY([0])\n    ]\n  })\n)\n\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nerrors = format_errors_data(errors_data, country_iso)\n\n\n\n\n\n\n\nave_errors = format_ave_errors_data(ave_errors_data, country_iso)\n\n\n\n\n\n\n\n\nweight = get_weights_per_challenge(mapping_countries_weights, challenge).filter(d =&gt; d.Name == country)[0].Weight\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REGARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_errors_data,\n    format_ave_errors_data,\n    mapping_countries_weights,\n    get_countries_per_challenge,\n    get_weights_per_challenge,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\""
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "Our team employed a comprehensive methodology utilizing both standard econometric models and machine learning type models to accurately nowcast the target variables. Specifically, we utilized a combination of three econometric models, including RegArima, Exponential Smoothing (ETS), and Dynamic Factor Models (DFM), as well as two machine learning models, XGBoost and Long Short-Term Memory (LSTM) models, to ensure robust and accurate forecasting. While we applied the same five model classes across all three challenges, including PPI, PVI, and Tourism, we tailored the specific datasets and parameters to each challenge to optimize model performance. This approach allowed us to leverage the strengths of both traditional econometric models and cutting-edge ML techniques to achieve the best possible forecasting results."
  },
  {
    "objectID": "methodology.html#regarima",
    "href": "methodology.html#regarima",
    "title": "Methodology",
    "section": "Regarima",
    "text": "Regarima\n\nIntroduction\nARIMA modelling is a common type of time models used to capture internal information of a series, wether is is stationary or non stationary. ARIMA models offer some advantages in this exercise: they are relatively simple, easy to interpret, and therefore provide a useful benchmark for more complex models. As standard ARIMA models do not include external information, we use the extended version RegARIMA with external regressors (regression model with ARIMA errors):\n\\[\ny_t = c + \\sum_{i=1}^{p}\\alpha_i x^i_{t}+u_t\n\\] \\[\n\\phi(L)(u_t) = \\theta(L)(\\varepsilon_t)\n\\]\nAdditional regressors used in this project are of two types:\n\nEconomic variables presented in the data section. REGARIMA models must keep parsimonious (contrary to other methods implemented in this project), so relevant variables are selected through standard selection procedures or a priori.\nOutlier variables such as level-shift or additive outilers to control for atypical observations.\n\nModels are applied to the first differentiation of the variable of interest.\n\n\nAutomatic identification and nowcasting\nWe use the RJdemetra package (the TRAMO part) that provide an easy way to identify and estimate RegARIMA models with high flexibility on parameters.\n\nwe allow for automatic detection of outliers on the estimation period in order to avoid large bias on coefficients. Without adding outliers, “covid” points, for instance, would totally distort coefficients. Outliers identified through this procedure could in addition be used in other methods\ncomputation time is fast (a few seconds for the whole set of countries)\nexternal regressors are selected independently, a priori or through standard variable selection procedure.\n\nThe final nowcast value is provided by the projection of the model at horizon 1, 2 or 3, depending on the challenge and the position in the month.\n\n\nSeasonal adjustment for tourism\nFor tourism, the seasonal component is very strong and may not be the same as the explanatory variables. An X13 pre-treatment is applied to seasonnally adjust and correct for trading days the target variable (Number of nights spent at tourist accommodation establishments) and the potential explanatory variables. This treatment also provides a prediction for the seasonal coefficient of the nowcasted month.\nNext, seasonally adjusted variables are put in the REGARIMA model. The final step involves nowcasting the “raw value” by dividing the SA forecast by the projected seasonal coefficient."
  },
  {
    "objectID": "methodology.html#dynamic-factor-models",
    "href": "methodology.html#dynamic-factor-models",
    "title": "Methodology",
    "section": "Dynamic Factor Models",
    "text": "Dynamic Factor Models\n\nIntroduction\nDynamic Factor Models (DFM) are a powerful and versatile approach for nowcasting, which involves extracting latent factors from a large set of observed economic or financial indicators. These latent factors capture the underlying dynamics of the data and are used to generate forecasts or predictions in real-time.\nDFM are based on the idea that a small number of unobservable factors drive the behavior of a large number of observed variables. These factors represent the common underlying movements in the data and can be interpreted as representing the state of the economy or the financial system at a given point in time. By estimating these latent factors from historical data, DFM allows us to capture the relevant information embedded in the observed indicators and use it to generate accurate nowcasts.\nA standard dynamic factor model involves 2 main equations.\n\nThe factor equation (Equation 1): This equation represents the dynamics of the latent factors, which are unobservable variables that capture the common underlying movements in the observed data. The factor equation is usually specified as a dynamic system allowing the unobserved factors \\(F_t\\) to evolve according to a \\(VAR(p)\\) process, and can be written as: \\[\nF_t = \\sum_{j=1}^pA_{j}F_{t-j} + \\eta_t, \\qquad \\eta_t \\sim N(0, \\Sigma_{0})\n\\tag{1}\\] where \\(F_t\\) represents the vector of latent factors at time \\(t\\), \\(A_{j}\\) is the (state-) transition matrix capturing the dynamics of the factors at lag \\(j\\), \\(F_{t-1}\\) is the vector of factors at time \\(t-1\\), and \\(\\Sigma_{0}\\) is the (state-) covariance matrix.\nThe measurement equation (Equation 2): This equation links the latent factors to the observed variables. It specifies how the observed variables are generated from the latent factors and can be written as: \\[\nX_t = \\Lambda F_{t} + \\xi_t, \\qquad \\xi_t \\sim N(0, R)\n\\tag{2}\\] where \\(X_t\\) represents the vector of observed variables at time \\(t\\), \\(\\Lambda\\) is the factor loading matrix, linking the factors to the observed variables, \\(\\xi_t\\) is the vector of measurement errors at time \\(t\\) and \\(R\\) is the (measurement-) covariance matrix.\n\n\n\n\n\n\n\n\n\nMatrices\nSizes\nDescriptions\n\n\n\n\n\\(F_t\\)\n\\(n \\times 1\\)\nVector of factors at time t \\((f_{1t}, \\ldots, f_{nt})'\\)\n\n\n\\(A_j\\)\n\\(r \\times r\\)\nState transition matrix at lag \\(j\\)\n\n\n\\(\\Sigma_0\\)\n\\(r \\times r\\)\nState covariance matrix\n\n\n\\(X_t\\)\n\\(n \\times 1\\)\nVector of observed series at time t \\((x_{1t}, \\ldots, x_{nt})'\\)\n\n\n\\(\\Lambda\\)\n\\(n \\times r\\)\nFactor loading matrix\n\n\n\\(R\\)\n\\(n \\times n\\)\nMeasurement covariance matrix\n\n\n\\(r\\)\n\\(1 \\times 1\\)\nNumber of factors\n\n\n\\(p\\)\n\\(1 \\times 1\\)\nNumber of lags\n\n\n\n\n\nData used and estimation\nFor the estimation of our Dynamics Factor Models (DFM), we utilized three main sources of data to capture different aspects of the economic and financial activity. These data sources include Eurostat data for economic activity, financial data obtained using the Yahoo API for financial activity, and Google Trends data for capturing more recent evolutions1. By incorporating these three main sources of data, we aim to capture different aspects of the economic and financial activity, ranging from long-term trends to short-term fluctuations and recent evolutions. This multi-source data approach allows us to build a more comprehensive and robust DFM model, which can provide more accurate and timely nowcasting predictions for the variables of interest.1 You can refer to the Data section for more extensive details on the data that has been used.\nFor the estimation of our various Dynamics Factor Models (DFM), we relied on the “dfms” package in R, a powerful and user-friendly tool for estimating DFMs from time series data. The “dfms” package provides convenient and efficient methods for DFM estimation, making it an invaluable resource for our nowcasting project. Its user-friendly interface and optimized algorithms make it easy to implement and customize DFM models, while its efficient computational capabilities enable us to handle large datasets with ease. We really want to thanks Sebastian Krantz, the creator of this package.\nTo ensure the robustness and accuracy of our DFM estimation, we took several steps beforehand the estimation pipeline of the “dfms” package. Since there are no trend or intercept terms in Equation 1 and Equation 2, we made \\(X_t\\) stationary by taking a first difference. Note that \\(X_t\\) is also standardized (scaled and centered) automatically by the “dfms” package.\nWe also pay attention to the availability of the data to ensure that each observed series have sufficient data for estimation. If any series have inadequate data, it is removed from the estimation process to prevent biased results. We also account for potential collinearities that could occur among several economic variables. Highly correlated series (\\(\\rho \\geq 0.9999\\)) are removed to mitigate multicollinearity issues and improve estimation accuracy.\nTo determine the optimal values for the number of lags and factors in our DFM models, we use the Bai and Ng (2002) criteria, which provides statistical guidelines for selecting these parameters. We set a maximum limit of 4 lags and 2 factors for computational efficiency reasons.\nWe initiate the estimation process from February 2005 for all challenges, and for the TOURISM challenge, we performed a seasonal adjustment on the target series prior to estimation in order to account for any seasonal patterns in the data.\n\n\nNowcasting\nOnce the DFM is estimated (\\(A_j\\), \\(\\Sigma_0\\), \\(\\Lambda\\), \\(R\\)), it can be used for nowcasting by forecasting the latent factors using the factor equation, and then generating nowcasts for the observed variables using the measurement equation. The predictions can be updated in real-time as new data becomes available, allowing for timely and accurate predictions of the variables of interest."
  },
  {
    "objectID": "methodology.html#ets",
    "href": "methodology.html#ets",
    "title": "Methodology",
    "section": "ETS",
    "text": "ETS\nExponential smoothing models are a class of models where forecasts are linear combinations of past values, with the weights decaying exponentially as the observations get older. Therefore, the more recent the observation is, the higher the associated weight is. Moreover, exponential smoothing models do not require any external data.\nThe exponential smoothing models used are a combination of three components:\n\nAn error: additive (\\(A\\)) or multiplicative (\\(M\\)).\nA trend: additive (\\(A\\)), multiplicative (\\(M\\)), damped (\\(A_d\\) or \\(M_d\\)) or absent (\\(N\\)).\nA seasonality: additive (\\(A\\)), multiplicative \\(M\\) or absent (\\(N\\)). The seasonal component is only used with tourism data.\n\nSee Figure 1 for the description of the model.\n\n\n\n\n\n\n\n(a) Additive error\n\n\n\n\n\n\n\n\n\n(b) Multiplicative error\n\n\n\n\n\n\nSource: Hyndman, R.J., & Athanasopoulos, G. (2018).\n\n\nFigure 1: Exponential smoothing models.\n\n\nFor each series, the model is selected minimising the Akaike’s Information Criterion (AIC) and parameters are estimated maximising the likelihood."
  },
  {
    "objectID": "methodology.html#xgboost",
    "href": "methodology.html#xgboost",
    "title": "Methodology",
    "section": "XGBoost",
    "text": "XGBoost\n\nIntroduction\nXGBoost is a powerful algorithm that has gained popularity in the field of machine learning due to its ability to handle complex interactions between variables and its flexibility in handling various types of data. In the context of Eurostat’s nowcasting competition, we utilized the XGBoost algorithm to predict the values of the Producer Price Index, the Producer Volume Index and the Number of nights spent at tourist accommodation establishments for most European countries. We will delve here into the technicalities of the XGBoost approach, and how we tailored it to our specific nowcasting problem.\n\n\nXGBoost Algorithm\nXGBoost is a gradient boosting algorithm that is particularly well suited for regression and classification problems. It works by building a sequence of decision trees, each tree trying to correct the errors of the previous tree. During the training process, the algorithm iteratively adds decision trees to the model, where each new tree is fit on the residuals (i.e., the errors) of the previous trees. The final prediction is made by adding the output of all the trees.\nTo control for overfitting, XGBoost uses a combination of L1 and L2 regularization, also known as “lasso” and “ridge” regularization, respectively. These regularization methods add a penalty term to the loss function, which forces the algorithm to find simpler models. L1 regularization shrinks the less important features’ coefficients to zero, while L2 regularization encourages the coefficients to be small, but does not set them to zero. By using both methods, XGBoost is able to produce models that are both accurate and interpretable.\nAnother key feature of XGBoost is its ability to handle missing values. Rather than imputing missing values with a fixed value or mean, XGBoost assigns them a default direction in the split, allowing the algorithm to learn how to handle missing values during the training process.\nOverall, the XGBoost algorithm has proven to be a powerful tool in the field of machine learning, and its ability to handle large datasets and complex interactions between variables make it well-suited for nowcasting problems like the Eurostat competition.\n\n\nTransforming Time Series\nTo apply the XGBoost algorithm to our nowcasting problem, we first transformed the time series data into a larger dataset tailored for the algorithm. We gathered several sources of data, including financial series, macroeconomic series, and surveys, and created a dataset where each row corresponds to a value per country and per date with many explanatory variables. We added lagged versions of the target variable and some of the explanatory variables as additional features. By doing so, we captured the time series properties of the data and made it suitable for the XGBoost algorithm.\n\n\nGrid Search for Hyperparameters\nTo obtain optimal results from the XGBoost algorithm, we used a grid search technique to find the best combination of hyperparameters for each model. We experimented with various values of hyperparameters, including learning rate, maximum depth, and subsample ratio, to determine which combination of parameters resulted in the best performance. The grid search enabled us to identify the best hyperparameters for the model, allowing us to obtain the most accurate predictions. We did not differentiate the hyperparameters for each country as it would have likely caused even more overfitting.\n\n\nTraining XGBoost for Nowcasting\nTo predict our 3 indicators for each country, we trained an XGBoost model for each country independently. We randomly split the data into training and testing sets and trained the model on the training set using the optimal hyperparameters obtained from the grid search. We evaluated the model’s performance on the testing set using various metrics such as mean squared error and mean absolute error."
  },
  {
    "objectID": "methodology.html#lstm",
    "href": "methodology.html#lstm",
    "title": "Methodology",
    "section": "LSTM",
    "text": "LSTM\nLSTM, or Long Short-Term Memory, is a type of recurrent neural network that is particularly well-suited for modeling time series data. Unlike traditional feedforward neural networks, which process input data in a single pass, recurrent neural networks can maintain a “memory” of previous inputs and use this information to make better predictions.\nLSTM takes this a step further by introducing “gates” that can selectively remember or forget previous inputs based on their importance to the current prediction. These gates allow the model to capture longer-term dependencies in the data, making it especially effective for time series forecasting tasks.\nDuring the training process, the LSTM model is fed a sequence of inputs, with each input representing a timestep in the time series. The model then generates a corresponding output for each timestep, which is compared to the actual value to compute a loss function. The weights of the model are updated through backpropagation, where the gradient of the loss function is propagated backwards through the network.\nOne of the challenges of using LSTMs for time series forecasting is selecting an appropriate window size, or the number of previous timesteps that the model should consider when making each prediction. A larger window size can capture longer-term trends in the data, but may also introduce more noise and complicate the training process. A smaller window size, on the other hand, may be more sensitive to short-term fluctuations in the data, but may not capture longer-term trends as effectively.\nIn the context of the Eurostat competition, the LSTM approach was used to predict the value of several economic indicators, including the Producer Price Index, the Producer Volume Index and the Number of nights spent at tourist accommodation establishments. The time series data for each country was transformed into a format that was suitable for LSTM training, with each row representing a single timestep in the time series and the columns representing the various input features.\nThe LSTM model was trained independently for each country, with a grid search used to find the optimal hyperparameters for each model. Overall, the LSTM approach proved to be a powerful tool for time series forecasting, and its ability to capture long-term dependencies in the data made it particularly well-suited for the nowcasting problem at hand."
  },
  {
    "objectID": "tourism.html",
    "href": "tourism.html",
    "title": "Number of nights spent at tourist accommodation establishments challenge",
    "section": "",
    "text": "challenge = \"TOURISM\"\nAccommodation statistics are a key part of the system of tourism statistics in the EU and have a long history of data collection. For this indicator, the benchmark will be the official figures on nights spent at tourist accommodation establishments by residents and non-residents.\nA night spent is each night a guest/tourist (resident or non-resident) actually spends (sleeps or stays) or is registered (his/her physical presence there being unnecessary) in a tourist accommodation establishment."
  },
  {
    "objectID": "tourism.html#next-forecast-for-a-given-country",
    "href": "tourism.html#next-forecast-for-a-given-country",
    "title": "Number of nights spent at tourist accommodation establishments challenge",
    "section": "Next forecast for a given country",
    "text": "Next forecast for a given country\n\nviewof country = Inputs.select(Object.values(country_map), {\n  label: html`&lt;b&gt;Select a country:&lt;/b&gt;`,\n  placeholder: \"Enter a country name\",\n  unique: true\n  })\n\n\n\n\n\n\n\n\n\naddTooltips(\nPlot.plot({\n  grid: true,\n  y: {\n    label: \"↑ Number of nights spent at tourist accommodation establishments\",\n    transform: d =&gt; d / 1e6\n  },  \n  x: {\n      label: \"Year\",\n      domain: range\n    },\n  marks: [\n    Plot.line(historical, {\n        x: \"date\", \n        y: \"values\", \n        stroke: \"black\",\n        title: (d) =&gt;\n                `${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })}\\n ${d.values / 1e6} millions `\n        }),\n    Plot.dot(predictions, {\n        x: \"date\", \n        y: \"values\",\n        fill: \"model\",\n        title:  (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values / 1e6} millions `\n        })\n  ],\n  color: {legend: true}\n})\n)\n\n\n\n\n\n\n\n\n\n\n\ndates = {\n  const data = historical.map(d =&gt; d.date)\n  data.push(predictions.map(d =&gt; d.date)[0])\n  return data  \n}\n\nviewof range = offsetInterval(dates, {\n  value: [ dates[dates.length-90], dates[dates.length-1] ],\n  format: ([a, b]) =&gt; htl.html`&lt;span ${{\n    style: \"display: flex; justify-content: space-between\"\n  }}&gt;\n    ${a.toISOString(\"en-UK\").slice(0, 10)}\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    ${b.toISOString(\"en-UK\").slice(0, 10)}\n  &lt;/span&gt;`\n})"
  },
  {
    "objectID": "tourism.html#country-specific-forecast-summary-by-model",
    "href": "tourism.html#country-specific-forecast-summary-by-model",
    "title": "Number of nights spent at tourist accommodation establishments challenge",
    "section": "Country-specific forecast summary by model",
    "text": "Country-specific forecast summary by model\n\nviewof form = Inputs.form({\n  model: Inputs.checkbox(models, {value: models}),\n  countries: Inputs.select([\"All\", ...Object.values(country_map)], {multiple: true, value: [\"All\"], width: 50, size: 1})\n})\n\n\n\n\n\n\n\nviewof rows = Inputs.table(summary_table,{\n  rows: 25,\n  maxWidth: 840,\n  multiple: false,\n  layout: \"fixed\"\n})\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nsummary_table = format_summary_table_data(pred, form.countries, form.model, country_map)\n\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REG-ARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_summary_table_data,\n    get_countries_per_challenge,\n    mapping_countries_weights,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\"\nimport {offsetInterval} from '@mootari/offset-slider'"
  },
  {
    "objectID": "post-mortem-pvi.html",
    "href": "post-mortem-pvi.html",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "",
    "text": "challenge = \"PVI\""
  },
  {
    "objectID": "post-mortem-pvi.html#past-predictions",
    "href": "post-mortem-pvi.html#past-predictions",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Past predictions",
    "text": "Past predictions\nThis interactive graph displays the historical forecasts generated by all of our models, as well as the actual observed value for the selected country.\n\naddTooltips(\n  Plot.plot({\n    grid: true,\n    y: {\n      label: \"↑ Producer volume in industry\",\n    },  \n    marks: [\n      Plot.line(historical, {\n          x: \"date\", \n          y: \"values\", \n          stroke: \"black\",\n          strokeWidth: 2,\n          title: (d) =&gt;\n                `${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })}\\n ${d.values} `\n          }),\n      Plot.line(predictions, {\n          x: \"date\", \n          y: \"values\",\n          stroke: \"model\",\n          title: (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values} `\n          })\n    ],\n    color: {legend: true}\n  })\n)"
  },
  {
    "objectID": "post-mortem-pvi.html#square-relative-error-per-month",
    "href": "post-mortem-pvi.html#square-relative-error-per-month",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Square relative error per month",
    "text": "Square relative error per month\nThis graph illustrates the square relative error for each of the models used in the challenge. The square relative error is a measure of the accuracy of a forecast that takes into account the magnitude of the error, as well as the level of the first official release being predicted.\n\\[\nSRE = \\left(\\frac{Y - R}{R}\\right)^2\n\\] where \\(R\\) is the first official release and \\(Y\\) the nowcasted value.\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      axis: null\n    },\n    y: {\n      grid: true,\n      label: \"↑ SRE\"\n    },\n    color: {\n      legend: true\n    },\n    fx: {\n      label: null,\n      tickFormat: (d) =&gt; d.toLocaleString('en-US', { month: 'long', year: 'numeric' }),    \n      reverse: false\n    },\n    facet: {data: errors, x: \"Date\"},\n    marks: [\n      Plot.barY(errors, {\n          x: \"Model\", \n          y: \"Errors\", \n          fill: \"Model\",\n          sort: {\n            x: {value: \"y\", reverse: true}\n          },\n          title: (d) =&gt;\n              `${d.Model}: \\n ${d.Errors} `\n        }),\n      Plot.ruleY([0])\n    ]\n  })\n)"
  },
  {
    "objectID": "post-mortem-pvi.html#mean-square-relative-error",
    "href": "post-mortem-pvi.html#mean-square-relative-error",
    "title": "Post-mortem analysis of our forecasts per country",
    "section": "Mean square relative error",
    "text": "Mean square relative error\nThis interactive graph displays the mean square relative error for each of the models used in the challenge, ranked by their performance from the least accurate to the most accurate. The mean square relative error is a statistical measure that provides an average of the square relative error across all the forecasts made by a given model.\nThese errors can be weighted by a factor, as was the case in the official evaluation of the challenge. The role of the weights is to reflect the difficulty of predicting the point estimate of the target variable for the corresponding country.\n\\[\nMSRE = \\frac{1}{n}\\sum_\\limits{i=1}^n\\left(\\frac{Y_i - R_i}{R_i}\\right)^2\n\\]\n\nviewof doweighted = Inputs.toggle({label: \"Weighted mean\", value: false})\n\n\n\n\n\n\n\naddTooltips(\n  Plot.plot({\n    x: {\n      domain: d3.sort(ave_errors, d =&gt; -d.MSRE).map(d =&gt; d.Entries),\n      label: null\n    },\n    y: {\n      grid: true,\n      transform: doweighted ? d =&gt; d * weight : null\n    },\n    color: {\n      legend: true\n    },\n    marks: [\n      Plot.barY(ave_errors, {\n                x: \"Entries\", \n                y: \"MSRE\",\n                fill: \"Entries\",\n                sort: {\n                        x: {value: \"y\", reverse: true}\n                      },\n                title: (d) =&gt;\n                    `${d.Entries}: \\n ${doweighted ?  Math.round(d.MSRE * weight * 10000) / 10000 :  Math.round(d.MSRE * 10000) / 10000} (n = ${d.N}) `\n                }),\n      Plot.ruleY([0])\n    ]\n  })\n)\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nerrors = format_errors_data(errors_data, country_iso)\n\n\n\n\n\n\n\nave_errors = format_ave_errors_data(ave_errors_data, country_iso)\n\n\n\n\n\n\n\n\nweight = get_weights_per_challenge(mapping_countries_weights, challenge).filter(d =&gt; d.Name == country)[0].Weight\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REGARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_errors_data,\n    format_ave_errors_data,\n    mapping_countries_weights,\n    get_countries_per_challenge,\n    get_weights_per_challenge,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\""
  },
  {
    "objectID": "LICENCE.html",
    "href": "LICENCE.html",
    "title": "European Statistics Awards for Nowcasting",
    "section": "",
    "text": "EUROPEAN UNION PUBLIC LICENCE v. 1.2\n                  EUPL © the European Union 2007, 2016\nThis European Union Public Licence (the ‘EUPL’) applies to the Work (as defined below) which is provided under the terms of this Licence. Any use of the Work, other than as authorised under this Licence is prohibited (to the extent such use is covered by a right of the copyright holder of the Work).\nThe Work is provided under the terms of this Licence when the Licensor (as defined below) has placed the following notice immediately following the copyright notice for the Work:\n    Licensed under the EUPL\nor has expressed by any other means his willingness to license under the EUPL.\n\nDefinitions\n\nIn this Licence, the following terms have the following meaning:\n\n‘The Licence’: this Licence.\n‘The Original Work’: the work or software distributed or communicated by the Licensor under this Licence, available as Source Code and also as Executable Code as the case may be.\n‘Derivative Works’: the works or software that could be created by the Licensee, based upon the Original Work or modifications thereof. This Licence does not define the extent of modification or dependence on the Original Work required in order to classify a work as a Derivative Work; this extent is determined by copyright law applicable in the country mentioned in Article 15.\n‘The Work’: the Original Work or its Derivative Works.\n‘The Source Code’: the human-readable form of the Work which is the most convenient for people to study and modify.\n‘The Executable Code’: any code which has generally been compiled and which is meant to be interpreted by a computer as a program.\n‘The Licensor’: the natural or legal person that distributes or communicates the Work under the Licence.\n‘Contributor(s)’: any natural or legal person who modifies the Work under the Licence, or otherwise contributes to the creation of a Derivative Work.\n‘The Licensee’ or ‘You’: any natural or legal person who makes any usage of the Work under the terms of the Licence.\n‘Distribution’ or ‘Communication’: any act of selling, giving, lending, renting, distributing, communicating, transmitting, or otherwise making available, online or offline, copies of the Work or providing access to its essential functionalities at the disposal of any other natural or legal person.\n\n\nScope of the rights granted by the Licence\n\nThe Licensor hereby grants You a worldwide, royalty-free, non-exclusive, sublicensable licence to do the following, for the duration of copyright vested in the Original Work:\n\nuse the Work in any circumstance and for all usage,\nreproduce the Work,\nmodify the Work, and make Derivative Works based upon the Work,\ncommunicate to the public, including the right to make available or display the Work or copies thereof to the public and perform publicly, as the case may be, the Work,\ndistribute the Work or copies thereof,\nlend and rent the Work or copies thereof,\nsublicense rights in the Work or copies thereof.\n\nThose rights can be exercised on any media, supports and formats, whether now known or later invented, as far as the applicable law permits so.\nIn the countries where moral rights apply, the Licensor waives his right to exercise his moral right to the extent allowed by law in order to make effective the licence of the economic rights here above listed.\nThe Licensor grants to the Licensee royalty-free, non-exclusive usage rights to any patents held by the Licensor, to the extent necessary to make use of the rights granted on the Work under this Licence.\n\nCommunication of the Source Code\n\nThe Licensor may provide the Work either in its Source Code form, or as Executable Code. If the Work is provided as Executable Code, the Licensor provides in addition a machine-readable copy of the Source Code of the Work along with each copy of the Work that the Licensor distributes or indicates, in a notice following the copyright notice attached to the Work, a repository where the Source Code is easily and freely accessible for as long as the Licensor continues to distribute or communicate the Work.\n\nLimitations on copyright\n\nNothing in this Licence is intended to deprive the Licensee of the benefits from any exception or limitation to the exclusive rights of the rights owners in the Work, of the exhaustion of those rights or of other applicable limitations thereto.\n\nObligations of the Licensee\n\nThe grant of the rights mentioned above is subject to some restrictions and obligations imposed on the Licensee. Those obligations are the following:\nAttribution right: The Licensee shall keep intact all copyright, patent or trademarks notices and all notices that refer to the Licence and to the disclaimer of warranties. The Licensee must include a copy of such notices and a copy of the Licence with every copy of the Work he/she distributes or communicates. The Licensee must cause any Derivative Work to carry prominent notices stating that the Work has been modified and the date of modification.\nCopyleft clause: If the Licensee distributes or communicates copies of the Original Works or Derivative Works, this Distribution or Communication will be done under the terms of this Licence or of a later version of this Licence unless the Original Work is expressly distributed only under this version of the Licence — for example by communicating ‘EUPL v. 1.2 only’. The Licensee (becoming Licensor) cannot offer or impose any additional terms or conditions on the Work or Derivative Work that alter or restrict the terms of the Licence.\nCompatibility clause: If the Licensee Distributes or Communicates Derivative Works or copies thereof based upon both the Work and another work licensed under a Compatible Licence, this Distribution or Communication can be done under the terms of this Compatible Licence. For the sake of this clause, ‘Compatible Licence’ refers to the licences listed in the appendix attached to this Licence. Should the Licensee’s obligations under the Compatible Licence conflict with his/her obligations under this Licence, the obligations of the Compatible Licence shall prevail.\nProvision of Source Code: When distributing or communicating copies of the Work, the Licensee will provide a machine-readable copy of the Source Code or indicate a repository where this Source will be easily and freely available for as long as the Licensee continues to distribute or communicate the Work.\nLegal Protection: This Licence does not grant permission to use the trade names, trademarks, service marks, or names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the copyright notice.\n\nChain of Authorship\n\nThe original Licensor warrants that the copyright in the Original Work granted hereunder is owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.\nEach Contributor warrants that the copyright in the modifications he/she brings to the Work are owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.\nEach time You accept the Licence, the original Licensor and subsequent Contributors grant You a licence to their contributions to the Work, under the terms of this Licence.\n\nDisclaimer of Warranty\n\nThe Work is a work in progress, which is continuously improved by numerous Contributors. It is not a finished work and may therefore contain defects or ‘bugs’ inherent to this type of development.\nFor the above reason, the Work is provided under the Licence on an ‘as is’ basis and without warranties of any kind concerning the Work, including without limitation merchantability, fitness for a particular purpose, absence of defects or errors, accuracy, non-infringement of intellectual property rights other than copyright as stated in Article 6 of this Licence.\nThis disclaimer of warranty is an essential part of the Licence and a condition for the grant of any rights to the Work.\n\nDisclaimer of Liability\n\nExcept in the cases of wilful misconduct or damages directly caused to natural persons, the Licensor will in no event be liable for any direct or indirect, material or moral, damages of any kind, arising out of the Licence or of the use of the Work, including without limitation, damages for loss of goodwill, work stoppage, computer failure or malfunction, loss of data or any commercial damage, even if the Licensor has been advised of the possibility of such damage. However, the Licensor will be liable under statutory product liability laws as far such laws apply to the Work.\n\nAdditional agreements\n\nWhile distributing the Work, You may choose to conclude an additional agreement, defining obligations or services consistent with this Licence. However, if accepting obligations, You may act only on your own behalf and on your sole responsibility, not on behalf of the original Licensor or any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against such Contributor by the fact You have accepted any warranty or additional liability.\n\nAcceptance of the Licence\n\nThe provisions of this Licence can be accepted by clicking on an icon ‘I agree’ placed under the bottom of a window displaying the text of this Licence or by affirming consent in any other similar way, in accordance with the rules of applicable law. Clicking on that icon indicates your clear and irrevocable acceptance of this Licence and all of its terms and conditions.\nSimilarly, you irrevocably accept this Licence and all of its terms and conditions by exercising any rights granted to You by Article 2 of this Licence, such as the use of the Work, the creation by You of a Derivative Work or the Distribution or Communication by You of the Work or copies thereof.\n\nInformation to the public\n\nIn case of any Distribution or Communication of the Work by means of electronic communication by You (for example, by offering to download the Work from a remote location) the distribution channel or media (for example, a website) must at least provide to the public the information requested by the applicable law regarding the Licensor, the Licence and the way it may be accessible, concluded, stored and reproduced by the Licensee.\n\nTermination of the Licence\n\nThe Licence and the rights granted hereunder will terminate automatically upon any breach by the Licensee of the terms of the Licence.\nSuch a termination will not terminate the licences of any person who has received the Work from the Licensee under the Licence, provided such persons remain in full compliance with the Licence.\n\nMiscellaneous\n\nWithout prejudice of Article 9 above, the Licence represents the complete agreement between the Parties as to the Work.\nIf any provision of the Licence is invalid or unenforceable under applicable law, this will not affect the validity or enforceability of the Licence as a whole. Such provision will be construed or reformed so as necessary to make it valid and enforceable.\nThe European Commission may publish other linguistic versions or new versions of this Licence or updated versions of the Appendix, so far this is required and reasonable, without reducing the scope of the rights granted by the Licence. New versions of the Licence will be published with a unique version number.\nAll linguistic versions of this Licence, approved by the European Commission, have identical value. Parties can take advantage of the linguistic version of their choice.\n\nJurisdiction\n\nWithout prejudice to specific agreement between parties,\n\nany litigation resulting from the interpretation of this License, arising between the European Union institutions, bodies, offices or agencies, as a Licensor, and any Licensee, will be subject to the jurisdiction of the Court of Justice of the European Union, as laid down in article 272 of the Treaty on the Functioning of the European Union,\nany litigation arising between other parties and resulting from the interpretation of this License, will be subject to the exclusive jurisdiction of the competent court where the Licensor resides or conducts its primary business.\n\n\nApplicable Law\n\nWithout prejudice to specific agreement between parties,\n\nthis Licence shall be governed by the law of the European Union Member State where the Licensor has his seat, resides or has his registered office,\nthis licence shall be governed by Belgian law if the Licensor has no seat, residence or registered office inside a European Union Member State.\n\nAppendix\n‘Compatible Licences’ according to Article 5 EUPL are:\n\nGNU General Public License (GPL) v. 2, v. 3\nGNU Affero General Public License (AGPL) v. 3\nOpen Software License (OSL) v. 2.1, v. 3.0\nEclipse Public License (EPL) v. 1.0\nCeCILL v. 2.0, v. 2.1\nMozilla Public Licence (MPL) v. 2\nGNU Lesser General Public Licence (LGPL) v. 2.1, v. 3\nCreative Commons Attribution-ShareAlike v. 3.0 Unported (CC BY-SA 3.0) for works other than software\nEuropean Union Public Licence (EUPL) v. 1.1, v. 1.2\nQuébec Free and Open-Source Licence — Reciprocity (LiLiQ-R) or Strong Reciprocity (LiLiQ-R+).\n\nThe European Commission may update this Appendix to later versions of the above licences without producing a new version of the EUPL, as long as they provide the rights granted in Article 2 of this Licence and protect the covered Source Code from exclusive appropriation.\nAll other changes or additions to this Appendix require the production of a new EUPL version."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The challenge",
    "section": "",
    "text": "In the area of nowcasting, the European Statistics Awards Programme aims to discover promising methodologies and potential external data sources that could, now or in the future, be used to improve the timeliness of key EU economic indicators. Better timeliness is a recurring demand for official statistics so there are obvious benefits to developing new approaches which obtain more accurate estimates within a shorter interval. Even where a satisfactorily accurate point estimate is already available, alternative methodologies carry significant potential secondary benefits like reduced cost, improved robustness and applicability in cases where a developed statistical system is still not established.\nThe 2022 round of the Nowcasting awards is divided into 3 separate competitions, each focusing on the nowcasting of one economic indicator:"
  },
  {
    "objectID": "index.html#our-team",
    "href": "index.html#our-team",
    "title": "The challenge",
    "section": "Our team",
    "text": "Our team\nWe represent INSEE, the French National Institute of Statistics and Economic Studies, for this challenge. Our team is composed of 5 members:\n\nThomas Faria, Data Scientist in the Innovation Lab in Data Science\nPierre Leblanc, Head of Division in the Short-term Statistics Department\nInès Moutachaker, Research Analyst in the Department of Economic Studies\nAntoine Palazzolo, Data Scientist in the Innovation Lab in Data Science\nAlain Quartier-La-Tente, Research analyst in the Department of Economic Studies"
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "The challenge",
    "section": "Licence",
    "text": "Licence\nThis work is licensed under the European Union Public Licence 1.2.\nSee the code on Github."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "The challenge",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nOn behalf of our team, we would like to express our gratitude to:\n\nINSEE and our hierarchy for providing us with the time and resources to participate in this challenge and supporting our research efforts.\nThe IT innovation team at INSEE for providing us with the SSPCloud platform, which not only enabled us to perform our data science analysis with ease but also provided us with an efficient computing environment.\nThe various teams at INSEE whom we reached out to for their invaluable advice and guidance throughout the competition.\nThe organizers of this challenge for creating a stimulating and engaging platform to showcase our skills.\nThe creators of the RJDemetra package, which provided us with powerful tools for seasonal adjustment of time series data, enhancing the accuracy of our models.\nSebastian Krantz, the creator of the dfms package, for openly sharing this valuable resource and providing a user-friendly and efficient tool for estimating Dynamics Factor Models (DFM) in R, which significantly facilitated our nowcasting analysis.\n\nThank you all for your support and contributions to our success in this endeavor."
  },
  {
    "objectID": "pvi.html",
    "href": "pvi.html",
    "title": "Production volume in industry challenge",
    "section": "",
    "text": "challenge = \"PVI\"\nThe monthly PVI indicator represents the production index in industry. The objective of the index is to measure changes in the volume of output at monthly intervals. It provides a measure of the volume trend in value added over a given reference period. The production index is calculated in the form of a Laspeyres type index."
  },
  {
    "objectID": "pvi.html#next-forecast-for-a-given-country",
    "href": "pvi.html#next-forecast-for-a-given-country",
    "title": "Production volume in industry challenge",
    "section": "Next forecast for a given country",
    "text": "Next forecast for a given country\n\nviewof country = Inputs.select(Object.values(country_map), {\n  label: html`&lt;b&gt;Select a country:&lt;/b&gt;`,\n  placeholder: \"Enter a country name\",\n  unique: true\n  })\n\n\n\n\n\n\n\n\n\naddTooltips(\nPlot.plot({\n  grid: true,\n  y: {\n    label: \"↑ Production volume in industry\",\n  },  \n  x: {\n      label: \"Year\",\n      domain: range\n    },\n  marks: [\n    Plot.line(historical, {\n        x: \"date\", \n        y: \"values\", \n        stroke: \"black\",\n        title: (d) =&gt;\n              `${d.date.toLocaleString(\"en-UK\", {\n                month: \"long\",\n                year: \"numeric\"\n              })}\\n ${d.values} `\n        }),\n    Plot.dot(predictions, {\n        x: \"date\", \n        y: \"values\",\n        fill: \"model\",\n        title:  (d) =&gt;\n                `${d.model}\\n ${d.date.toLocaleString(\"en-UK\", {\n                  month: \"long\",\n                  year: \"numeric\"\n                })} : ${d.values} `\n        })\n  ],\n  color: {legend: true}\n})\n)\n\n\n\n\n\n\n\n\n\n\n\ndates = {\n  const data = historical.map(d =&gt; d.date)\n  data.push(predictions.map(d =&gt; d.date)[0])\n  return data  \n}\n\nviewof range = offsetInterval(dates, {\n  value: [ dates[dates.length-90], dates[dates.length-1] ],\n  format: ([a, b]) =&gt; htl.html`&lt;span ${{\n    style: \"display: flex; justify-content: space-between\"\n  }}&gt;\n    ${a.toISOString(\"en-UK\").slice(0, 10)}\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    ${b.toISOString(\"en-UK\").slice(0, 10)}\n  &lt;/span&gt;`\n})"
  },
  {
    "objectID": "pvi.html#country-specific-forecast-summary-by-model",
    "href": "pvi.html#country-specific-forecast-summary-by-model",
    "title": "Production volume in industry challenge",
    "section": "Country-specific forecast summary by model",
    "text": "Country-specific forecast summary by model\n\nviewof form = Inputs.form({\n  model: Inputs.checkbox(models, {value: models}),\n  countries: Inputs.select([\"All\", ...Object.values(country_map)], {multiple: true, value: [\"All\"], width: 50, size: 1})\n})\n\n\n\n\n\n\n\nviewof rows = Inputs.table(summary_table,{\n  rows: 25,\n  maxWidth: 840,\n  multiple: false,\n  layout: \"fixed\"\n})\n\n\n\n\n\n\n\n\nhistorical = format_historical_data(data, country_iso)\n\n\n\n\n\n\n\npredictions = format_pred_data(pred, country_iso)\n\n\n\n\n\n\n\nsummary_table = format_summary_table_data(pred, form.countries, form.model, country_map)\n\n\n\n\n\n\n\n\ncountry_map = get_countries_per_challenge(mapping_countries_weights, challenge)\n\n\n\n\n\n\n\ncountry_iso = Object.keys(country_map).find(key =&gt; country_map[key] === country);\n\n\n\n\n\n\n\nmodels = [\"REG-ARIMA\", \"DFM\", \"ETS\", \"XGBOOST\", \"LSTM\"]\n\n\n\n\n\n\n\n\nimport { \n    format_historical_data,\n    format_pred_data,\n    format_summary_table_data,\n    get_countries_per_challenge,\n    mapping_countries_weights,\n     } from \"./utils/utils.qmd\"\n\n\n\n\n\n\n\nimport {addTooltips} from \"@mkfreeman/plot-tooltip\"\nimport {offsetInterval} from '@mootari/offset-slider'"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "We take great pride in our dedication to using exclusively open data sources in our modeling efforts, which was a fundamental aspect of our approach during the challenge. While some proprietary data sources may have had greater predictive power, we firmly believed that utilizing open data sources was crucial to promoting the principles of transparency and reproducibility in our modeling efforts. By leveraging publicly available data, we were able to derive nowcasts of key economic indicators while ensuring that our work can be easily replicated and validated by others in the official statistics community. This approach not only provided us with a robust foundation for our models but also served to promote the values of open science, data transparency, and reproducibility.\nDuring the challenge, we utilized three primary sources of data to inform our modeling efforts. The first source was economic data from the Eurostat database, which provided us with a comprehensive overview of the economic situation in the European Union. The second source of data was financial data, which provided us with valuable insights into the financial context surrounding each of the challenges. This data included stock prices, exchange rates, and other financial indicators that were useful in predicting economic trends and identifying potential risks. Finally, we also used Google Trends data to capture the most recent trends and shifts in consumer behavior. This data enabled us to monitor changes in search volume for specific keywords, which served as an early warning system for sudden changes in consumer sentiment and preferences. Overall, our use of these three distinct sources of data allowed us to develop a comprehensive understanding of the economic landscape and to generate nowcasts of the 3 target variables."
  },
  {
    "objectID": "data.html#sec-data-eurostat",
    "href": "data.html#sec-data-eurostat",
    "title": "Data",
    "section": "Economic data from Eurostat database",
    "text": "Economic data from Eurostat database\nWe use classic macroeconomic variables provided to Eurostat by European countries and available on Eurostat website. These series are automatically retrieved from Eurostat database through its API.\n\nProducer prices in industry:\nProducer Price in Industry (PPI) refers to the average price that domestic producers receive for the goods and services they produce. This indicator measures changes in the price of goods and services at the producer level, and it is considered an important leading indicator of inflation.\nSpecificities:\n-   The PPI challenge refers to this indicator for a particular NACE\n-   Total on domestic market (target variable)\n-   Division level of NACE and MIGs\nImport prices in industry:\nImport prices in industry, also known as industrial import price index (IPI), refer to the cost of goods and services imported into a country for use in production. This indicator reflects changes in the prices of imported raw materials, intermediate goods, and capital equipment, and it is influenced by factors such as exchange rates, global commodity prices, and trade policies.\nSpecificities:\n-   Total\n-   Division level of CPA and MIGs\nProduction index in industry :\nThe Production Index in Industry (or Production Volume in Industry - PVI) is a measure of the physical output of the industrial sector of an economy. It tracks changes in the volume of goods produced over time, and it is considered an important indicator of the health and performance of the manufacturing sector. The production index can be used to assess trends in productivity, capacity utilization, and competitiveness.\nSpecificities:\n-   The PVI challenge refers to this indicator for a particular NACE\n-   Total\n-   Intermediary goods (MIG_ING)\nHarmonised Index of Consumer Prices on a few products\nThe Harmonised Index of Consumer Prices (HICP) is a measure of inflation that is used to compare price changes across the European Union. It tracks the average change over time in the prices of goods and services that households consume, including food, housing, transportation, and healthcare. The HICP is calculated using a harmonised methodology that ensures comparability across EU member states, and it is published on a monthly basis by Eurostat. It is a key indicator of price stability.\nBusiness survey in industry:\nThe Business Survey in Industry is a survey conducted by Eurostat to gather information on the business conditions and expectations of companies in the manufacturing sector. The survey covers a range of topics, including production, new orders, inventories, employment, prices, and investment, and it is conducted on a monthly basis across the European Union. The data collected from the survey can be used to assess the current and future state of the manufacturing sector, to identify sector-specific challenges and opportunities, and to inform policymaking and business decision-making.\nCovered by the survey:\n-   Industrial confidence indicator\n-   Production development observed over the past 3 months\n-   Production expectations over the next 3 months\n-   Employment expectations over the next 3 months\n-   Assessment of order-book levels\n-   Assessment of the current level of stocks of finished products\n-   Selling price expectations over the next 3 months\nConsumer survey in industry:\nThe Consumer Survey in Industry is a survey conducted by Eurostat to gather information on the consumer sentiment and behavior in the European Union. The survey covers a range of topics, including household income, savings, spending intentions, and major purchases, and it is conducted on a monthly basis. The data collected from the survey can be used to assess consumer confidence, to identify trends in consumer spending and saving patterns, and to inform policymaking and business decision-making. The Consumer Survey in Industry is an important indicator of the overall health of the economy, as consumer spending is a major driver of economic activity.\nCovered by the survey:\n-   Financial situation over the last 12 months\n-   Financial situation over the next 12 months\n-   General economic situation over the last 12 months\n-   General economic situation over the next 12 months\n-   Price trends over the last 12 months\n-   Price trends over the next 12 months\n-   Unemployment expectations over the next 12 months\n-   The current economic situation is adequate to make major purchases\n-   Major purchases over the next 12 months\n-   The current economic situation is adequate for savings\n-   Savings over the next 12 months\n-   Statement on financial situation of household\n-   Consumer confidence indicator\nNumber of nights spent at tourist accommodation establishments\nThe number of nights spent at tourist accommodation establishments is a measure of the volume of tourism activity in a country. It refers to the total number of nights that guests spend in all types of tourist accommodation establishments, including hotels, campsites, holiday homes, and other types of accommodation. This indicator is important for assessing the contribution of tourism to the economy, as well as for monitoring the performance and competitiveness of the tourism sector.\nSpecificities:\n-   The TOURISM challenge refers to this indicator"
  },
  {
    "objectID": "data.html#financial-data-from-yahoo-finance",
    "href": "data.html#financial-data-from-yahoo-finance",
    "title": "Data",
    "section": "Financial data from Yahoo Finance",
    "text": "Financial data from Yahoo Finance\nYahoo Finance is a popular online platform for financial information and investment tools. It provides a wide range of financial data, including real-time stock prices, historical price charts, news articles, analyst ratings, and financial statements for publicly traded companies. We used its API to get the latest financial data to improve our short-term predictions.\n\nEuro/Dollar exchange rate\nThe Euro/Dollar exchange rate represents the value of one euro in terms of US dollars. It is a widely followed currency pair in the foreign exchange market, as it reflects the relative strength of two of the world’s largest economies. Movements in the exchange rate can be influenced by a range of factors, such as interest rate differentials, inflation expectations, political developments, and global economic trends. The exchange rate can impact international trade, investment flows, and the competitiveness of exports and imports, making it a key indicator for businesses, investors, and policymakers alike.\nBrent Crude Oil Stock Price\nThe Brent Crude Oil Last Day Financial Futures Stock Price is a benchmark for the price of crude oil from the North Sea, which is used as a pricing reference for approximately two-thirds of the world’s traded crude oil. As a financial futures contract, it allows investors to trade the price of oil without actually buying or selling the physical commodity. The stock price reflects the market’s perception of supply and demand dynamics, geopolitical risks, and other macroeconomic factors that impact the oil market.\nS&P 500 Index Stock Price\nThe S&P 500 Index stock is a market capitalization-weighted index of 500 leading publicly traded companies in the United States. It is widely considered to be a barometer of the US stock market’s performance, providing investors with a broad-based measure of the economy’s health and direction. The S&P 500 index includes companies from a range of sectors, such as technology, healthcare, finance, and energy, making it a diversified indicator of the US equity market.\nEuro stoxx 50 Index Stock Price\nThe Euro Stoxx 50 Index stock is a market capitalization-weighted index of 50 leading blue-chip companies from 12 Eurozone countries. It is designed to reflect the performance of the Eurozone’s most liquid and largest companies across a range of industries, including banking, energy, consumer goods, and healthcare. As a widely recognized benchmark of the Eurozone equity market, the Euro Stoxx 50 Index stock is used by investors and analysts to track market trends, benchmark portfolio performance, and identify investment opportunities. Movements in the index are influenced by a range of factors, such as economic growth prospects, monetary policy decisions, geopolitical risks, and corporate earnings announcements.\nCAC40 Index Stock Price\nThe CAC 40 Index Stock is a benchmark index of the top 40 companies listed on the Euronext Paris Stock Exchange, representing a broad range of industries such as energy, finance, healthcare, and technology. It is the most widely used indicator of the French equity market’s performance and is considered one of the leading indices in Europe. The CAC 40 Index Stock is weighted by market capitalization and is closely monitored by investors and analysts as an indicator of economic health and growth prospects in France. Movements in the index can be influenced by a variety of factors, such as geopolitical risks, macroeconomic indicators, and company-specific news."
  },
  {
    "objectID": "data.html#google-trends",
    "href": "data.html#google-trends",
    "title": "Data",
    "section": "Google Trends",
    "text": "Google Trends\nGoogle Trends is a free online tool provided by Google that allows users to explore the popularity of search queries over time and across different regions and languages. It provides valuable insights into the behavior of internet users, the topics they are interested in, and the evolution of search trends over time.\nNevertheless, the use of Google Trends data as a tool for economic analysis needs to be done carefully. Google Trends provides Search Volume Indices (SVI) based on search ratios, with the initial search volume for a category or topic at a given time divided by the total number of searches at that date. However, changes in the denominator (total searches) can induce biases as internet use has evolved since 2004.\nWe implemented an approach to address this downward bias by extracting a common component from concurrent time series using Principal Component Analysis (PCA) on the log-SVI series long-term trends filtered out using an HP filter. The rescaled first component obtained from the long-term log-SVIs is assumed to capture the common long-term trend, and it is subtracted from the log-SVIs. This approach can help to remove the downward bias common to all Google Trends variables and improve their economic predictive power. More information in this paper.\nObserved categories:\n\nManufacturing\nIndustrial Materials & Equipment\nFuel Economy & Gas Prices\nHotels & Accommodations\nTravel Agencies & Services\nVacation Offers\nMountain & Ski Resorts"
  },
  {
    "objectID": "data.html#other-data",
    "href": "data.html#other-data",
    "title": "Data",
    "section": "Other data",
    "text": "Other data\n\nElectricity prices\nEmber.org provides European wholesale electricity price data that can be used to analyze electricity market trends, monitor price volatility, and inform investment decisions. The data is sourced from various market operators and exchanges across Europe and covers a wide range of countries and regions.\n\n\nCalendar data\nWe retrieve the number of weekend days per month to include it as a feature to our models.\n\n\nLeading national indicators\n\nGermany developed some experimental indicators on activity. We use the daily Truck toll mileage index accessible on Destatis website.\n\n\nThe Weekly WIFO Economic Index is a measure of the real economic activity of the Austrian economy. We use its industrial production component.\n\n\n\nOther potential interesting data sources (not identified in open data sources)\n\nHistorical Purchasing manager’s index by country\nLondon metal exchange indices\nDaily electricity consumption by industrial firms country by country\n…"
  }
]